{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ff417-ad4e-487e-8752-155a858dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import shap\n",
    "\n",
    "# 设置全局字体为Arial，并调整大小\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 40\n",
    "plt.rcParams['axes.titlesize'] = 44\n",
    "plt.rcParams['xtick.labelsize'] = 36\n",
    "plt.rcParams['ytick.labelsize'] = 36\n",
    "plt.rcParams['legend.fontsize'] = 36\n",
    "plt.rcParams['figure.titlesize'] = 44\n",
    "\n",
    "# 定义浅色调色板\n",
    "colors = {\n",
    "    'RandomForest': ('#4daf4a', '#006400'),\n",
    "    'XGBoost': ('#377eb8', '#00468B'),\n",
    "    'ElasticNet': ('#e41a1c', '#990000'),\n",
    "    'SVR': ('#984ea3', '#5f0080'),\n",
    "    'GradientBoosting': ('#ff7f00', '#b35900'),\n",
    "}\n",
    "\n",
    "# 自定义特征选择器\n",
    "class CustomFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=10):\n",
    "        self.k = k\n",
    "        self.selector = SelectKBest(mutual_info_regression, k=self.k)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.selector.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.selector.transform(X)\n",
    "\n",
    "# 读取Excel文件\n",
    "excel_path = r\"D:\\张雨林\\电子科大合作文章\\力学三步筛选后特征\\力学特征建模.xlsx\"\n",
    "output_folder = os.path.dirname(excel_path)\n",
    "df = pd.read_excel(excel_path, sheet_name=\"Sheet1\", header=0)\n",
    "\n",
    "def plot_prediction(y_train, y_train_pred, y_test, y_test_pred, name, r2_train, r2_test):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    plt.scatter(y_train, y_train_pred, color=colors[name][0], alpha=0.3, label='Training Set', s=120)\n",
    "    plt.scatter(y_test, y_test_pred, color=colors[name][1], alpha=0.6, label='Test Set', s=120)\n",
    "    \n",
    "    min_val = min(y_train.min(), y_test.min())\n",
    "    max_val = max(y_train.max(), y_test.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=3)\n",
    "    \n",
    "    plt.xlabel('Observed Values', fontsize=40)\n",
    "    plt.ylabel('Predicted Values', fontsize=40)\n",
    "    \n",
    "    plt.text(0.05, 0.95, f'Train R² = {r2_train:.3f}\\nTest R² = {r2_test:.3f}', \n",
    "             transform=plt.gca().transAxes, fontsize=36, \n",
    "             verticalalignment='top', fontweight='bold')\n",
    "    \n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.gca().set_facecolor('#f0f0f0')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.title(name, fontsize=44, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='major', labelsize=36)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_folder, f'{name}_comparison_plot.png')\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved plot for {name} at {output_path}\")\n",
    "    plt.close()\n",
    "  \n",
    "def plot_feature_importance(importance_df, model_name):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(6), \n",
    "                palette=[colors[model_name][0], colors[model_name][1]], edgecolor='black')\n",
    "    plt.title(f'Top 6 Features - {model_name}', fontweight='bold', fontsize=44)\n",
    "    plt.xlabel('Importance Score', fontweight='bold', fontsize=40)\n",
    "    plt.ylabel('', fontweight='bold')\n",
    "    plt.tick_params(axis='both', which='major', labelsize=36)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_folder, f'{model_name}_Feature_Importance.png')\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved feature importance plot at {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 修改相关性热图绘图函数\n",
    "def plot_correlation_heatmap(corr_matrix, model_name):\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='PuOr', vmin=-1, vmax=1, center=0, \n",
    "                square=True, linewidths=0.5, cbar_kws={\"shrink\": .8}, fmt='.2f',\n",
    "                annot_kws={\"size\": 30})\n",
    "    plt.title(f'Correlation Heatmap of Top 6 Features - {model_name}', fontweight='bold', fontsize=44)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=36)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_folder, f'{model_name}_Correlation_Heatmap.png')\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved correlation heatmap at {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_shap_values(model, X, feature_names, model_name, feature_importance):\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    \n",
    "    # 按照特征重要性排序\n",
    "    feature_order = feature_importance['Feature'].tolist()\n",
    "    feature_idx = [feature_names.index(f) for f in feature_order if f in feature_names]\n",
    "    \n",
    "    plt.figure(figsize=(14, 12))\n",
    "    shap.summary_plot(shap_values[:, feature_idx], X.iloc[:, feature_idx], \n",
    "                      plot_type=\"dot\", feature_names=[feature_names[i] for i in feature_idx], \n",
    "                      show=False, plot_size=(14, 12), color=colors[model_name][0])\n",
    "    plt.title(f'SHAP Feature Impact - {model_name}', fontweight='bold', fontsize=44)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=36)\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_folder, f'{model_name}_shap_plot.png')\n",
    "    plt.savefig(output_path, dpi=600, bbox_inches='tight')\n",
    "    print(f\"Saved SHAP plot for {model_name} at {output_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# 数据预处理\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "df = df.fillna(0)\n",
    "\n",
    "# 分离特征和目标变量\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "print(f\"\\nInitial number of features: {X.shape[1]}\")\n",
    "\n",
    "# 分层抽样分割数据集（确保目标变量分布一致）\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "y_binary = (y != 0).astype(int)  # 将连续目标变量转为二分类，用于分层抽样\n",
    "\n",
    "for train_index, val_index in sss.split(X, y_binary):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_test = y[train_index], y[val_index]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Test set size: {len(X_test)} samples\")\n",
    "\n",
    "# 定义模型管道（标准化→特征选择→模型训练）\n",
    "def create_pipeline(model):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selector', CustomFeatureSelector()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# 优化后的模型配置（超参数搜索范围）\n",
    "models = {\n",
    "    'XGBoost': (create_pipeline(xgb.XGBRegressor(random_state=42)), {\n",
    "        'feature_selector__k': [10, 15, 20, 25],\n",
    "        'model__n_estimators': [100, 200, 300, 400],\n",
    "        'model__max_depth': [3, 4, 5, 6],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__subsample': [0.8, 0.9, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'model__reg_alpha': [0, 0.1, 0.5],\n",
    "        'model__reg_lambda': [0, 0.1, 0.5]\n",
    "    }),\n",
    "    'ElasticNet': (create_pipeline(ElasticNet(random_state=42)), {\n",
    "        'feature_selector__k': [10, 15, 20, 25],\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    }),\n",
    "    'SVR': (create_pipeline(SVR()), {\n",
    "        'feature_selector__k': [10, 15, 20, 25],\n",
    "        'model__kernel': ['rbf', 'poly'],\n",
    "        'model__C': [0.1, 1, 10, 100],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__epsilon': [0.01, 0.1, 0.2]\n",
    "    }),\n",
    "    'RandomForest': (create_pipeline(RandomForestRegressor(random_state=42)), {\n",
    "        'feature_selector__k': [10, 15, 20, 25],\n",
    "        'model__n_estimators': [100, 200, 300, 400],\n",
    "        'model__max_depth': [None, 5, 10, 15],\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'GradientBoosting': (create_pipeline(GradientBoostingRegressor(random_state=42)), {\n",
    "        'feature_selector__k': [10, 15, 20, 25],\n",
    "        'model__n_estimators': [100, 200, 300, 400],\n",
    "        'model__max_depth': [3, 4, 5, 6],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__subsample': [0.8, 0.9, 1.0],\n",
    "    })\n",
    "}\n",
    "\n",
    "# 训练和评估模型（贝叶斯优化超参数）\n",
    "best_models = {}\n",
    "best_r2 = -np.inf\n",
    "best_model_name = ''\n",
    "results = {}  # 存储每个模型的性能指标和预测结果\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\n=== Training {name} Model ===\")\n",
    "    # 贝叶斯超参数搜索（5折交叉验证，重复3次）\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        params,\n",
    "        cv=RepeatedKFold(n_splits=5, n_repeats=3),\n",
    "        scoring='r2',  # 以R²为优化目标\n",
    "        n_jobs=-1,     # 并行计算（使用所有CPU核心）\n",
    "        n_iter=50,     # 搜索50组超参数组合\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    opt.fit(X_train, y_train)\n",
    "    best_model = opt.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    # 模型预测\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # 计算性能指标\n",
    "    r2_train = r2_score(y_train, y_train_pred)\n",
    "    r2_test = r2_score(y_test, y_test_pred)\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    # 保存结果\n",
    "    results[name] = {\n",
    "        'r2_train': r2_train,\n",
    "        'r2_test': r2_test,\n",
    "        'mae_train': mae_train,\n",
    "        'mae_test': mae_test,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'best_params': opt.best_params_\n",
    "    }\n",
    "    \n",
    "    # 打印性能结果\n",
    "    print(f\"{name} Performance:\")\n",
    "    print(f\"  Train R²: {r2_train:.3f}, Train MAE: {mae_train:.3f}\")\n",
    "    print(f\"  Test R²: {r2_test:.3f}, Test MAE: {mae_test:.3f}\")\n",
    "    print(f\"  Best Hyperparameters: {opt.best_params_}\")\n",
    "    \n",
    "    # 绘制预测对比图\n",
    "    plot_prediction(y_train, y_train_pred, y_test, y_test_pred, name, r2_train, r2_test)\n",
    "\n",
    "    # 更新最优模型\n",
    "    if r2_test > best_r2:\n",
    "        best_r2 = r2_test\n",
    "        best_model_name = name\n",
    "\n",
    "# 对最佳模型进行深度分析\n",
    "print(f\"\\n=== Best Model Analysis: {best_model_name} ===\")\n",
    "print(f\"Best Model Test R²: {best_r2:.3f}\")\n",
    "best_model = best_models[best_model_name]\n",
    "y_train_pred = results[best_model_name]['y_train_pred']\n",
    "y_test_pred = results[best_model_name]['y_test_pred']\n",
    "\n",
    "# -------------------------- 修复核心：预测数据行拼接（统一长度） --------------------------\n",
    "# 训练集预测数据（含样本ID和数据来源标识）\n",
    "train_pred_data = pd.DataFrame({\n",
    "    'Set': 'Training',  # 标识数据来源（训练集/测试集）\n",
    "    'Sample_ID': [f'Train_{i+1}' for i in range(len(y_train))],  # 唯一样本ID\n",
    "    'Actual_Value': y_train.values,  # 真实值\n",
    "    'Predicted_Value': y_train_pred,  # 预测值\n",
    "    'Residual': y_train.values - y_train_pred  # 残差（新增，便于误差分析）\n",
    "})\n",
    "\n",
    "# 测试集预测数据（格式与训练集一致）\n",
    "test_pred_data = pd.DataFrame({\n",
    "    'Set': 'Test',\n",
    "    'Sample_ID': [f'Test_{i+1}' for i in range(len(y_test))],\n",
    "    'Actual_Value': y_test.values,\n",
    "    'Predicted_Value': y_test_pred,\n",
    "    'Residual': y_test.values - y_test_pred\n",
    "})\n",
    "\n",
    "# 合并训练集和测试集数据（行拼接，长度统一）\n",
    "prediction_data = pd.concat([train_pred_data, test_pred_data], ignore_index=True)\n",
    "\n",
    "# 保存预测数据到CSV（用于Origin作图）\n",
    "prediction_csv_path = os.path.join(output_folder, f'{best_model_name}_Prediction_Data.csv')\n",
    "prediction_data.to_csv(prediction_csv_path, index=False, encoding='utf-8')\n",
    "print(f\"\\nSaved prediction data (with residual) to: {prediction_csv_path}\")\n",
    "\n",
    "# -------------------------- 特征重要性分析 --------------------------\n",
    "# 获取特征选择器选中的特征\n",
    "feature_selector = best_model.named_steps['feature_selector']\n",
    "selected_feature_indices = feature_selector.selector.get_support(indices=True)\n",
    "selected_feature_names = [feature_names[i] for i in selected_feature_indices]\n",
    "\n",
    "# 计算特征重要性（不同模型的重要性指标不同）\n",
    "if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "    # 树模型（XGBoost、RandomForest、GradientBoosting）\n",
    "    importances = best_model.named_steps['model'].feature_importances_\n",
    "elif hasattr(best_model.named_steps['model'], 'coef_'):\n",
    "    # 线性模型（ElasticNet）：用系数绝对值表示重要性\n",
    "        importances = np.abs(best_model.named_steps['model'].coef_)\n",
    "else:\n",
    "    # SVR等无法直接获取重要性的模型\n",
    "    print(f\"Cannot directly calculate feature importance for {best_model_name}, using mutual info scores instead\")\n",
    "    importances = feature_selector.selector.scores_[selected_feature_indices]\n",
    "\n",
    "# 整理特征重要性数据\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': selected_feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 保存特征重要性到CSV\n",
    "importance_csv_path = os.path.join(output_folder, f'{best_model_name}_Feature_Importance.csv')\n",
    "importance_df.to_csv(importance_csv_path, index=False, encoding='utf-8')\n",
    "print(f\"Saved feature importance data to: {importance_csv_path}\")\n",
    "\n",
    "# 绘制Top6特征重要性图\n",
    "plot_feature_importance(importance_df, best_model_name)\n",
    "\n",
    "# -------------------------- 相关性分析（Top6特征） --------------------------\n",
    "top6_features = importance_df['Feature'].head(6).tolist()\n",
    "# 提取训练集中Top6特征的原始数据\n",
    "X_train_top6 = pd.DataFrame(X_train, columns=feature_names)[top6_features]\n",
    "# 计算相关性矩阵\n",
    "corr_matrix = X_train_top6.corr()\n",
    "\n",
    "# 保存相关性矩阵到CSV\n",
    "correlation_csv_path = os.path.join(output_folder, f'{best_model_name}_Top6_Features_Correlation.csv')\n",
    "corr_matrix.to_csv(correlation_csv_path, encoding='utf-8')\n",
    "print(f\"Saved Top6 features correlation matrix to: {correlation_csv_path}\")\n",
    "\n",
    "# 绘制相关性热图\n",
    "plot_correlation_heatmap(corr_matrix, best_model_name)\n",
    "\n",
    "# -------------------------- SHAP值分析（仅树模型支持） --------------------------\n",
    "if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "    # 提取测试集中选中的特征数据（用于SHAP解释）\n",
    "    X_test_selected = pd.DataFrame(X_test, columns=feature_names)[selected_feature_names]\n",
    "    # 绘制SHAP特征影响图\n",
    "    plot_shap_values(\n",
    "        model=best_model.named_steps['model'],\n",
    "        X=X_test_selected,\n",
    "        feature_names=selected_feature_names,\n",
    "        model_name=best_model_name,\n",
    "        feature_importance=importance_df\n",
    "    )\n",
    "else:\n",
    "    print(f\"SHAP analysis is only supported for tree-based models (XGBoost/RandomForest/GradientBoosting), skipping for {best_model_name}\")\n",
    "\n",
    "# -------------------------- 所有模型性能汇总 --------------------------\n",
    "# 整理性能数据（R²、MAE）\n",
    "performance_data = []\n",
    "for model_name, result in results.items():\n",
    "    performance_data.append({\n",
    "        'Model': model_name,\n",
    "        'Train_R²': result['r2_train'],\n",
    "        'Test_R²': result['r2_test'],\n",
    "        'Train_MAE': result['mae_train'],\n",
    "        'Test_MAE': result['mae_test'],\n",
    "        'Best_Feature_Count': result['best_params']['feature_selector__k']\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data).sort_values('Test_R²', ascending=False)\n",
    "\n",
    "# 保存性能汇总到CSV\n",
    "performance_csv_path = os.path.join(output_folder, 'All_Models_Performance_Summary.csv')\n",
    "performance_df.to_csv(performance_csv_path, index=False, encoding='utf-8')\n",
    "print(f\"\\nSaved all models performance summary to: {performance_csv_path}\")\n",
    "\n",
    "# 打印最终汇总信息\n",
    "print(\"\\n=== Final Summary ===\")\n",
    "print(\"All generated files are saved to:\", output_folder)\n",
    "print(\"\\nModel Performance Ranking (by Test R²):\")\n",
    "for idx, row in performance_df.iterrows():\n",
    "    print(f\"{row['Model']}: Test R² = {row['Test_R²']:.3f}, Test MAE = {row['Test_MAE']:.3f}\")\n",
    "print(f\"\\nBest Model: {best_model_name} (Test R² = {best_r2:.3f})\")\n",
    "print(\"All plots and data tables have been generated successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
